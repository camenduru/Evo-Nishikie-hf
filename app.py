import random

from PIL import Image, ImageFilter
from controlnet_aux import LineartDetector
from diffusers import EulerDiscreteScheduler
import gradio as gr
import numpy as np
import spaces
import torch

# torch._inductor.config.conv_1x1_as_mm = True
# torch._inductor.config.coordinate_descent_tuning = True
# torch._inductor.config.epilogue_fusion = False
# torch._inductor.config.coordinate_descent_check_all_directions = True
from evo_nishikie_v1 import load_evo_nishikie


DESCRIPTION = """# ğŸŸ Evo-Nishikie
ğŸ¤— [ãƒ¢ãƒ‡ãƒ«ä¸€è¦§](https://huggingface.co/SakanaAI) | ğŸ“ [ãƒ–ãƒ­ã‚°](https://sakana.ai/evo-ukiyoe/) | ğŸ¦ [Twitter](https://twitter.com/SakanaAILabs)

[Evo-Nishikie](https://huggingface.co/SakanaAI/Evo-Nishikie-v1)ã¯[Sakana AI](https://sakana.ai/)ãŒæ•™è‚²ç›®çš„ã§é–‹ç™ºã—ãŸæµ®ä¸–çµµã«ç‰¹åŒ–ã—ãŸç”»åƒç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚
å…¥åŠ›ã—ãŸå˜è‰²æ‘ºã®æµ®ä¸–çµµï¼ˆå¢¨æ‘ºçµµç­‰ï¼‰ã‚’æ—¥æœ¬èªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«æ²¿ã£ã¦å¤šè‰²æ‘ºã®æµ®ä¸–çµµï¼ˆéŒ¦çµµï¼‰é¢¨ã«å¤‰æ›ã—ãŸç”»åƒã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã‚ˆã‚Šè©³ã—ãã¯ã€ä¸Šè¨˜ã®ãƒ–ãƒ­ã‚°ã‚’ã”å‚ç…§ãã ã•ã„ã€‚
"""
if not torch.cuda.is_available():
    DESCRIPTION += "\n<p>Running on CPU ğŸ¥¶ This demo may not work on CPU.</p>"

MAX_SEED = np.iinfo(np.int32).max

device = "cuda" if torch.cuda.is_available() else "cpu"

NUM_IMAGES_PER_PROMPT = 1
SAFETY_CHECKER = True
if SAFETY_CHECKER:
    from safety_checker import StableDiffusionSafetyChecker
    from transformers import CLIPFeatureExtractor

    safety_checker = StableDiffusionSafetyChecker.from_pretrained(
        "CompVis/stable-diffusion-safety-checker"
    ).to(device)
    feature_extractor = CLIPFeatureExtractor.from_pretrained(
        "openai/clip-vit-base-patch32"
    )

    def check_nsfw_images(
        images: list[Image.Image],
    ) -> tuple[list[Image.Image], list[bool]]:
        safety_checker_input = feature_extractor(images, return_tensors="pt").to(device)
        has_nsfw_concepts = safety_checker(
            images=[images], clip_input=safety_checker_input.pixel_values.to(device)
        )

        return images, has_nsfw_concepts


pipe = load_evo_nishikie(device)
pipe.scheduler = EulerDiscreteScheduler.from_config(
    pipe.scheduler.config, use_karras_sigmas=True,
)
# pipe.unet.to(memory_format=torch.channels_last)
# pipe.controlnet.to(memory_format=torch.channels_last)
# pipe.vae.to(memory_format=torch.channels_last)
# # Compile the UNet, ControlNet and VAE.
# pipe.unet = torch.compile(pipe.unet, mode="max-autotune", fullgraph=True)
# pipe.controlnet = torch.compile(pipe.controlnet, mode="max-autotune", fullgraph=True)
# pipe.vae.decode = torch.compile(pipe.vae.decode, mode="max-autotune", fullgraph=True)

lineart_detector = LineartDetector.from_pretrained("lllyasviel/Annotators")
image_filter = ImageFilter.MedianFilter(size=3)
BINARY_THRESHOLD = 40


def randomize_seed_fn(seed: int, randomize_seed: bool) -> int:
    if randomize_seed:
        seed = random.randint(0, MAX_SEED)
    return seed


@spaces.GPU
@torch.inference_mode()
def generate(
    input_image: Image.Image,
    prompt: str,
    seed: int = 0,
    randomize_seed: bool = False,
    progress=gr.Progress(track_tqdm=True),
):
    pipe.to(device)

    lineart_image = lineart_detector(input_image, coarse=False, image_resolution=1024)
    lineart_image_filtered = lineart_image.filter(image_filter)
    conditioning_image = lineart_image_filtered.point(lambda p: 255 if p > BINARY_THRESHOLD else 0).convert("L")

    seed = int(randomize_seed_fn(seed, randomize_seed))
    generator = torch.Generator().manual_seed(seed)

    images = pipe(
        prompt=prompt + "æœ€é«˜å“è³ªã®è¼»ã®æµ®ä¸–çµµã€‚è¶…è©³ç´°ã€‚",
        negative_prompt="æš—ã„",
        image=conditioning_image,
        guidance_scale=7.0,
        controlnet_conditioning_scale=0.8,
        num_inference_steps=35,
        generator=generator,
        num_images_per_prompt=NUM_IMAGES_PER_PROMPT,
        output_type="pil",
    ).images

    if SAFETY_CHECKER:
        images, has_nsfw_concepts = check_nsfw_images(images)
        if any(has_nsfw_concepts):
            gr.Warning("NSFW content detected.")
            return Image.new("RGB", (512, 512), "WHITE"), seed
    return images[0], seed


examples = [
    ["./sample1.jpg", "å¥³æ€§ãŒã‚„ã‹ã‚“ã¨é‹ã‚’æŒã¡ã€å°å±‹ã®å‰ã«ç«‹ã£ã¦ã„ã¾ã™ã€‚èƒŒæ™¯ã«ã¯å®¤å†…ã§ä¼šè©±ã™ã‚‹äººã€…ãŒã„ã¾ã™ã€‚"],
    ["./sample2.jpg", "ç€ç‰©ã‚’ç€ãŸå¥³æ€§ãŒã€èµ¤ã‚“åŠã‚’æŠ±ãˆã€ã‚‚ã†ä¸€äººã®å­ã©ã‚‚ãŒæ‰‹æŠ¼ã—è»Šã‚’å¼•ã„ã¦ã„ã¾ã™ã€‚èƒŒæ™¯ã«ã¯æœ¨ãŒã‚ã‚Šã¾ã™ã€‚"],
    ["./sample3.jpg", "å¥³æ€§ãŒèŠ±æŸ„ã®ç€ç‰©ã‚’ç€ã¦ãŠã‚Šã€ä»–ã®äººç‰©ãŸã¡ãŒåº§ã‚ŠãªãŒã‚‰ä¼šè©±ã—ã¦ã„ã¾ã™ã€‚èƒŒæ™¯ã«ã¯å®¶ã®å†…éƒ¨ãŒã‚ã‚Šã¾ã™ã€‚"],
    ["./sample4.jpg", "èŠ±æŸ„ã‚„æ¨¡æ§˜å…¥ã‚Šã®ç€ç‰©ã‚’ç€ãŸç”·å¥³ãŒå®¤å†…ã§é›†ã¾ã‚Šã€ç…èŒ¶ã®æº–å‚™ã‚’ã—ã¦ã„ã¾ã™ã€‚èƒŒæ™¯ã«æœ¨æã®è£…é£¾ãŒã‚ã‚Šã¾ã™ã€‚"],
]

css = """
.gradio-container{max-width: 1380px !important}
h1{text-align:center}
"""
with gr.Blocks(css=css) as demo:
    gr.Markdown(DESCRIPTION)
    with gr.Row():
        with gr.Column():
            input_image = gr.Image(image_mode="RGB", type="pil", show_label=False)
            prompt = gr.Textbox(placeholder="æ—¥æœ¬èªã§ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚", show_label=False)
            submit = gr.Button()
            with gr.Accordion("è©³ç´°è¨­å®š", open=False):
                seed = gr.Slider(label="ã‚·ãƒ¼ãƒ‰å€¤", minimum=0, maximum=MAX_SEED, step=1, value=0)
                randomize_seed = gr.Checkbox(label="ãƒ©ãƒ³ãƒ€ãƒ ã«ã‚·ãƒ¼ãƒ‰å€¤ã‚’æ±ºå®š", value=True)
        with gr.Column():
            result = gr.Image(label="Evo-Nishikieã‹ã‚‰ã®ç”Ÿæˆçµæœ", type="pil", show_label=False)
    gr.Examples(examples=examples, inputs=[input_image, prompt], outputs=[result, seed], fn=generate)
    gr.on(
        triggers=[
            submit.click,
        ],
        fn=generate,
        inputs=[
            input_image,
            prompt,
            seed,
            randomize_seed,
        ],
        outputs=[result, seed],
        api_name="run",
    )
    gr.Markdown("""âš ï¸ æœ¬ãƒ¢ãƒ‡ãƒ«ã¯å®Ÿé¨“æ®µéšã®ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ã§ã‚ã‚Šã€æ•™è‚²ãŠã‚ˆã³ç ”ç©¶é–‹ç™ºã®ç›®çš„ã§ã®ã¿æä¾›ã•ã‚Œã¦ã„ã¾ã™ã€‚å•†ç”¨åˆ©ç”¨ã‚„ã€éšœå®³ãŒé‡å¤§ãªå½±éŸ¿ã‚’åŠã¼ã™å¯èƒ½æ€§ã®ã‚ã‚‹ç’°å¢ƒï¼ˆãƒŸãƒƒã‚·ãƒ§ãƒ³ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«ãªç’°å¢ƒï¼‰ã§ã®ä½¿ç”¨ã«ã¯é©ã—ã¦ã„ã¾ã›ã‚“ã€‚
                æœ¬ãƒ¢ãƒ‡ãƒ«ã®ä½¿ç”¨ã¯ã€åˆ©ç”¨è€…ã®è‡ªå·±è²¬ä»»ã§è¡Œã‚ã‚Œã€ãã®æ€§èƒ½ã‚„çµæœã«ã¤ã„ã¦ã¯ä½•ã‚‰ä¿è¨¼ã•ã‚Œã¾ã›ã‚“ã€‚
                Sakana AIã¯ã€æœ¬ãƒ¢ãƒ‡ãƒ«ã®ä½¿ç”¨ã«ã‚ˆã£ã¦ç”Ÿã˜ãŸç›´æ¥çš„ã¾ãŸã¯é–“æ¥çš„ãªæå¤±ã«å¯¾ã—ã¦ã€çµæœã«é–¢ã‚ã‚‰ãšã€ä¸€åˆ‡ã®è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚
                åˆ©ç”¨è€…ã¯ã€æœ¬ãƒ¢ãƒ‡ãƒ«ã®ä½¿ç”¨ã«ä¼´ã†ãƒªã‚¹ã‚¯ã‚’ååˆ†ã«ç†è§£ã—ã€è‡ªèº«ã®åˆ¤æ–­ã§ä½¿ç”¨ã™ã‚‹ã“ã¨ãŒå¿…è¦ã§ã™ã€‚
                ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸç”»åƒã¯ç”»åƒç”Ÿæˆã®ã¿ã«ä½¿ç”¨ã•ã‚Œã€ã‚µãƒ¼ãƒãƒ¼ä¸Šã«ä¿å­˜ã•ã‚Œã‚‹ã“ã¨ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚

                å‡ºå…¸ï¼šã‚µãƒ³ãƒ—ãƒ«ç”»åƒã¯ã™ã¹ã¦[æ—¥æœ¬å¤å…¸ç±ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆå›½æ–‡å­¦ç ”ç©¶è³‡æ–™é¤¨è”µï¼‰ã€çµµæœ¬ç‰ã‹ã¤ã‚‰ã€](http://codh.rois.ac.jp/pmjt/book/200013861/)ã‹ã‚‰å¼•ç”¨ã—ã¾ã—ãŸã€‚""")

demo.queue().launch()